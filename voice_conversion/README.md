# Voice Conversion Using Speech-to-Speech Neuro-Style Transfer

The paper goal its present a new voice conversion method based on a neural style transfer model of the mel-spectrogram.

# Basic information about the project

Main paper / reference: Ehab A. AlBadawy, Siwei Lyu, <"Voice Conversion Using Speech-to-Speech Neuro-Style Transfer">, University at Albany, SUNY, USA

Main dataset: [(https://groups.csail.mit.edu/sls/downloads/flickraudio/downloads.cgi)]

Original code: https://github.com/ebadawy/voice_conversion

slide: https://docs.google.com/presentation/d/1pgDC-qwCtOGZSIG5tjIRUbSUCfo6EeyqRD-j7djDP5E/edit#slide=id.g13331885fbe_0_5

Language: Python 

# Installation

pip install librosa

pip install tqdm

pip install webrtcvad

pip install nnmnkwii

# Executing / performing basic analysis

Provide information on how to execute the main code, how to obtain results, etc. Provide the name of the main scripts.

# Credits

14/06/2022 - Tatiane Ferraz Balbinot - your github URL

# References

Main reference: https://github.com/ebadawy/voice_conversion

Followed instructions: https://github.com/RussellSB/tt-vae-gan

WaveNet VoCoder source: https://github.com/r9y9/wavenet_vocoder
